{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PoemWriterAI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mozhgans/ML-Poetry/blob/main/PoemWriterAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJolM36nNiV7"
      },
      "source": [
        "# An example of what we are going to create. Some lines generated by the program.\n",
        "\n",
        "\n",
        "\n",
        "**I  every be that pull in i every i life go would be time the soul a how empty has i spread but be day of and it me will i life go would be has of and it me will i life go would be has of and it me will i life go would be has of and it me will i life go would be has of and it me will i life go would be has of and it me will i life go would be has of and it me will i life go would be.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wdxnEF7NiV8"
      },
      "source": [
        "# Importing the libraries\n",
        "We import the necessary libraries useful for tokenizing and padding of sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbhHrlp4NiV9"
      },
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow import keras\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_ga6-1_NiWB"
      },
      "source": [
        "\n",
        "# Preprocessing the Data\n",
        "Here, we will be tokenizing the lines of the poem and convert them to sequences of equal lengths\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8giaRLcNiWC"
      },
      "source": [
        "\n",
        "## Extracting the raw text from the file\n",
        "We read the text available in the file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcUB5SbONiWD"
      },
      "source": [
        "\n",
        "text_file_path = 'text'\n",
        "\n",
        "def get_raw_data_from_file( path ):\n",
        "    text = str()\n",
        "    with open(path, \"r\") as fd:\n",
        "        text += fd.read()\n",
        "    return text\n",
        "\n",
        "raw_text = get_raw_data_from_file( text_file_path )\n",
        "print( raw_text )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz0jtnIGNiWJ"
      },
      "source": [
        "## Tokenizing the lines of the poem\n",
        "We tokenize poem lines using the tensorflow.keras.preprocessing.text.Tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntS83-fINiWL"
      },
      "source": [
        "\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "corpus = raw_text.split( \"\\n\\n\" )\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len( tokenizer.word_index ) + 1\n",
        "\n",
        "input_sequences = []\n",
        "\n",
        "for line in corpus:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i + 1]\n",
        "        input_sequences.append(n_gram_sequence)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8me2eE-iNiWO"
      },
      "source": [
        "## Padding the sequences of tokenized lines\n",
        "We pad the sequences so as to give them equal lengths.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbAqJ2DSNiWP"
      },
      "source": [
        "\n",
        "sequence_lengths = list()\n",
        "for x in input_sequences:\n",
        "    sequence_lengths.append( len( x ) )\n",
        "max_sequence_len = max( sequence_lengths )\n",
        "\n",
        "input_sequences = np.array(pad_sequences(input_sequences,\n",
        "                                         maxlen=max_sequence_len+1, padding='pre'))\n",
        "x, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
        "y = keras.utils.to_categorical(y, num_classes=total_words)\n",
        "\n",
        "print( x[ 0 ] , x.shape )\n",
        "print( y[ 0 ]  , y.shape ) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OXw8q76NiWV"
      },
      "source": [
        "# Initializing and Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4zghLLkNiWY"
      },
      "source": [
        "## Defining the model schema\n",
        "We define the hyperparameters from our LSTM model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KagzC7gNiWY"
      },
      "source": [
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "\n",
        "dropout_rate = 0.3\n",
        "activation_func = keras.activations.relu\n",
        "\n",
        "SCHEMA = [\n",
        "\n",
        "    Embedding( total_words , 10, input_length=max_sequence_len ),\n",
        "    LSTM( 32 ) ,\n",
        "    Dropout(dropout_rate),\n",
        "    Dense( 32 , activation=activation_func ) ,\n",
        "    Dropout(dropout_rate),\n",
        "    Dense( total_words, activation=tf.nn.softmax )\n",
        "\n",
        "]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17CYg-awNiWb"
      },
      "source": [
        "## Compiling the model\n",
        "Compiling the Keras model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmMupZt1NiWd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "3b4692d0-54ee-4858-f60a-ab093517351d"
      },
      "source": [
        "\n",
        "model = keras.Sequential(SCHEMA)\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam() ,\n",
        "    loss=keras.losses.categorical_crossentropy ,\n",
        "    metrics=[ 'accuracy' ]\n",
        ")\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 202, 10)           3920      \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                5504      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 392)               12936     \n",
            "=================================================================\n",
            "Total params: 23,416\n",
            "Trainable params: 23,416\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QjVfLMiNiWi"
      },
      "source": [
        "## Training the model\n",
        "Training the model for 150 epochs over the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YGxyPa8NiWj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "48ee341d-382b-4881-d1dd-54444c0dc749"
      },
      "source": [
        "\n",
        "model.fit(\n",
        "    x,\n",
        "    y,\n",
        "    batch_size=50 ,\n",
        "    epochs=1,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1019/1019 [==============================] - 3s 3ms/sample - loss: 5.9536 - acc: 0.0461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f45ced709e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2aifTPuNiWn"
      },
      "source": [
        "## Saving the model\n",
        "Saving the model to a .h5 file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCehYsmNNiWn"
      },
      "source": [
        "\n",
        "model.save( 'model.h5' ) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP8GCVWUxLpf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1577
        },
        "outputId": "5eb11534-554b-4a98-d455-cb5067b7d656"
      },
      "source": [
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model_file( 'model.h5')\n",
        "tflite_model = converter.convert()\n",
        "open(\"model.tflite\", \"wb\").write(tflite_model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py:591: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.compat.v1.graph_util.extract_sub_graph\n",
            "INFO:tensorflow:Froze 8 variables.\n",
            "INFO:tensorflow:Converted 8 variables to const ops.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ConverterError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConverterError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-77408d2e7dcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_keras_model_file\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model.tflite\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m           \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m           \u001b[0moutput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m           **converter_kwargs)\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m       result = _toco_convert_graph_def(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_impl\u001b[0;34m(input_data, input_tensors, output_tensors, *args, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m   data = toco_convert_protos(model_flags.SerializeToString(),\n\u001b[1;32m    441\u001b[0m                              \u001b[0mtoco_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                              input_data.SerializeToString())\n\u001b[0m\u001b[1;32m    443\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str)\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       raise ConverterError(\n\u001b[0;32m--> 205\u001b[0;31m           \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\n\u001b[0m\u001b[1;32m    206\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;31m# Must manually cleanup files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConverterError\u001b[0m: TOCO failed. See console for info.\n2019-03-19 07:05:48.181240: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: ResourceGather\n2019-03-19 07:05:48.191805: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayV3\n2019-03-19 07:05:48.191879: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\n2019-03-19 07:05:48.191958: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayScatterV3\n2019-03-19 07:05:48.192020: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayV3\n2019-03-19 07:05:48.192034: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\n2019-03-19 07:05:48.192050: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\n2019-03-19 07:05:48.192073: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\n2019-03-19 07:05:48.192087: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\n2019-03-19 07:05:48.192101: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\n2019-03-19 07:05:48.192119: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\n2019-03-19 07:05:48.192145: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\n2019-03-19 07:05:48.192165: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\n2019-03-19 07:05:48.192186: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: LoopCond\n2019-03-19 07:05:48.192224: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayReadV3\n2019-03-19 07:05:48.192287: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\n2019-03-19 07:05:48.192298: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\n2019-03-19 07:05:48.192307: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\n2019-03-19 07:05:48.192318: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: ReadVariableOp\n2019-03-19 07:05:48.192328: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\n2019-03-19 07:05:48.192337: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\n2019-03-19 07:05:48.192361: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: ReadVariableOp\n2019-03-19 07:05:48.192393: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: ReadVariableOp\n2019-03-19 07:05:48.192419: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: ReadVariableOp\n2019-03-19 07:05:48.192453: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: ReadVariableOp\n2019-03-19 07:05:48.192474: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\n2019-03-19 07:05:48.192487: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\n2019-03-19 07:05:48.192516: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: ReadVariableOp\n2019-03-19 07:05:48.192547: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: ReadVariableOp\n2019-03-19 07:05:48.192580: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: ReadVariableOp\n2019-03-19 07:05:48.192612: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: ReadVariableOp\n2019-03-19 07:05:48.192631: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\n2019-03-19 07:05:48.192663: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\n2019-03-19 07:05:48.192710: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: ReadVariableOp\n2019-03-19 07:05:48.192755: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: ReadVariableOp\n2019-03-19 07:05:48.192792: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: ReadVariableOp\n2019-03-19 07:05:48.192838: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayWriteV3\n2019-03-19 07:05:48.192861: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\n2019-03-19 07:05:48.192879: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\n2019-03-19 07:05:48.192946: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Exit\n2019-03-19 07:05:48.192967: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArraySizeV3\n2019-03-19 07:05:48.192994: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayGatherV3\n2019-03-19 07:05:48.194188: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 130 operators, 225 arrays (0 quantized)\n2019-03-19 07:05:48.195227: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 130 operators, 225 arrays (0 quantized)\n2019-03-19 07:05:48.196729: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 122 operators, 225 arrays (0 quantized)\n2019-03-19 07:05:48.198384: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 122 operators, 225 arrays (0 quantized)\n2019-03-19 07:05:48.199407: F tensorflow/lite/toco/tooling_util.cc:627] Check failed: dim >= 1 (0 vs. 1)\nAborted (core dumped)\n\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXRBVTxfNiWq"
      },
      "source": [
        "# Making Predictions\n",
        "We define the predict method which takes two arguments :\n",
        "\n",
        "\n",
        "1.   `seed_text `: The starter text required for the model to build sentences.\n",
        "2.   `seed `: Number of words the generated sentence must contain.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3R28MVwNiWs"
      },
      "source": [
        "\n",
        "def predict(seed_text , seed=10 ):\n",
        "\n",
        "    for i in range( seed ):\n",
        "\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=\n",
        "        max_sequence_len , padding='pre')\n",
        "        predicted = model.predict_classes(token_list, verbose=0 )\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "\n",
        "    return seed_text\n",
        "\n",
        "print( predict( input( 'Enter some starter text ( I want ... ) : ') , int( input( 'Enter the desired length of the generated sentence : '))  ) )\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}